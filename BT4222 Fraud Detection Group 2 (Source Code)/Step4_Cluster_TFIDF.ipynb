{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c34f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words with highest average TF-IDF scores:\n",
      "Word: need, Average TF-IDF Score: 0.0014752111772180932\n",
      "Word: students, Average TF-IDF Score: 0.001375062831720171\n",
      "Word: school, Average TF-IDF Score: 0.0013743867915714653\n",
      "Word: talk, Average TF-IDF Score: 0.0013564229557085266\n",
      "Word: hours, Average TF-IDF Score: 0.0013250935102476298\n",
      "Word: watch, Average TF-IDF Score: 0.0013234540355467723\n",
      "Word: whats, Average TF-IDF Score: 0.0013159162675803228\n",
      "Word: everything, Average TF-IDF Score: 0.0013060607460929278\n",
      "Word: retweet, Average TF-IDF Score: 0.0013033056575228559\n",
      "Word: health, Average TF-IDF Score: 0.0012971842166679555\n",
      "Word: hope, Average TF-IDF Score: 0.0012904563279874783\n",
      "Word: family, Average TF-IDF Score: 0.001283820693426421\n",
      "Word: show, Average TF-IDF Score: 0.0012706558551509838\n",
      "Word: post, Average TF-IDF Score: 0.001258386288053139\n",
      "Word: change, Average TF-IDF Score: 0.0012565584152170778\n",
      "Word: night, Average TF-IDF Score: 0.0012491584578582854\n",
      "Word: story, Average TF-IDF Score: 0.0012484154838259135\n",
      "Word: times, Average TF-IDF Score: 0.001246351824807445\n",
      "Word: tomorrow, Average TF-IDF Score: 0.0012413411154378298\n",
      "Word: research, Average TF-IDF Score: 0.0012374767073076373\n",
      "Word: cant, Average TF-IDF Score: 0.0012366382356064798\n",
      "Word: nothing, Average TF-IDF Score: 0.0012233315249509402\n",
      "Word: tweet, Average TF-IDF Score: 0.001219277435138273\n",
      "Word: congrats, Average TF-IDF Score: 0.00121809475178664\n",
      "Word: care, Average TF-IDF Score: 0.0011869376325403835\n",
      "Word: start, Average TF-IDF Score: 0.0011819605041261203\n",
      "Word: theres, Average TF-IDF Score: 0.0011423717084310318\n",
      "Word: project, Average TF-IDF Score: 0.0011416778379884482\n",
      "Word: anything, Average TF-IDF Score: 0.001137306315345335\n",
      "Word: fun, Average TF-IDF Score: 0.0011368308322463267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "\n",
    "file_names = []\n",
    "cluster_num = 0 # Change this to match cluster\n",
    "for i in range(9):\n",
    "    file_names.append(f'cluster_{cluster_num}_{i}.txt')\n",
    "\n",
    "text = ''\n",
    "# Load the text file\n",
    "for name in file_names:\n",
    "    # For each file, open it in read mode\n",
    "    with open(name, 'r', encoding=\"utf-8\") as file:\n",
    "        # Read its contents and append to the text string\n",
    "        text += file.read() + '\\n'\n",
    "\n",
    "sentences = text.split(\"\\n\")\n",
    "\n",
    "additional_stopwords = []\n",
    "with open('added_stopwords.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    additional_stopwords = [line.strip() for line in file]\n",
    "\n",
    "# Define a function for custom preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    # Filter out stop words\n",
    "    stop_words = set(stopwords.words('english')).union(additional_stopwords)\n",
    "    # Filter out stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Get POS tags for filtered tokens\n",
    "    tagged_tokens = pos_tag(filtered_tokens)\n",
    "    # Filter out only nouns\n",
    "    nouns = [token for token, pos in tagged_tokens if pos.startswith('N')]\n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(nouns)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Preprocess each sentence in the list\n",
    "preprocessed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the preprocessed sentences\n",
    "vectorizer.fit(preprocessed_sentences)\n",
    "\n",
    "# Transform the sentences into TF-IDF vectors\n",
    "tfidf_vectors = vectorizer.transform(preprocessed_sentences)\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Calculate the average TF-IDF score for each word across all sentences\n",
    "average_tfidf_scores = tfidf_vectors.mean(axis=0)\n",
    "\n",
    "# Convert average TF-IDF scores to a dictionary with feature names as keys\n",
    "word_tfidf_dict = dict(zip(feature_names, average_tfidf_scores.tolist()[0]))\n",
    "\n",
    "# Sort the dictionary by TF-IDF score in descending order\n",
    "sorted_word_tfidf = sorted(word_tfidf_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "# Print the top N words with highest average TF-IDF scores\n",
    "top_n = 30 # Adjust the number of top words to display\n",
    "print(\"Top words with highest average TF-IDF scores:\")\n",
    "for word, score in sorted_word_tfidf[:top_n]:\n",
    "    print(f\"Word: {word}, Average TF-IDF Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041d912",
   "metadata": {},
   "source": [
    "## Analysis of Clusters\n",
    "### Cluster 0: \n",
    "Political: \n",
    "Top words included 'congress', 'pm', 'country', 'president', 'india', 'parkistan', 'nation' indicate that this cluster is mostly related to political matters, primarily those in Asia.\n",
    "\n",
    "### Cluster 1: \n",
    "Business:\n",
    "Words like 'work', 'team', 'support', 'business', 'project', 'job' are common words that are used in tweets that pertain to general business.\n",
    "\n",
    "Academic:\n",
    "Words like 'students', 'research', 'paper', 'science', 'article', 'event' tend to be related to the field of academics.\n",
    "\n",
    "### Cluster 2: \n",
    "Technology and Innovation:\n",
    "Words like \"technology\", \"ai\" , \"innovation\", \"python\", \"crypto\", \"industry\", \"tomorrow\", \"datascience\" and \"research\" focus on news, insights or developments in technology and similar fields\n",
    "\n",
    "### Cluster 3: \n",
    "Western Politics: \n",
    "Words like \"war\", \"country\", \"russia\", \"president\", \"countries\", \"peace\", \"conference\" suggest strong focus on geopolitical issues, particularly in a Western context. \n",
    "\n",
    "Public Health and Policies:\n",
    "Words like \"health\", \"treatment\", and \"covid19\" suggest these political bots may cover political topics related to public health policies and issues\n",
    "\n",
    "### Cluster 4: \n",
    "Everyday Topics:\n",
    "Words like 'watch', 'health', 'family', 'tomorrow', 'fun', 'night' tend to be common words that are used in everyday conversations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
