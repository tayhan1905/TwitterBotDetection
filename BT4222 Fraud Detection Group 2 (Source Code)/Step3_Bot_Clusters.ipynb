{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcdd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pd.read_csv(\"users.csv\")\n",
    "g = pd.read_csv(\"graph.csv\", float_precision='round_trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qelVIK7KptvY",
   "metadata": {
    "id": "qelVIK7KptvY"
   },
   "outputs": [],
   "source": [
    "bots = u[u['label'] == 1]\n",
    "bot_source = bots['source_user_id']\n",
    "bot_tweets = g[g['source_user_id'].isin(bot_source)]\n",
    "bot_embeddings = g[g['source_user_id'].isin(bot_source)]['tweet_embedding']\n",
    "embeddings = np.stack(g['tweet_embedding'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc72eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_embeddings_for_cluster(user_id):\n",
    "    user = g[g['source_user_id'] == user_id]\n",
    "    if user.size != 0:\n",
    "        embeddings = np.stack(user['tweet_embedding'].values)\n",
    "    else:\n",
    "        # if user did not make any tweets\n",
    "        embeddings = np.zeros((1,100))\n",
    "    return user_id, torch.mean(torch.from_numpy(embeddings), dim=0).numpy()\n",
    "\n",
    "# Apply the function to each unique source_user_id\n",
    "aggregated_embeddings = [aggregate_embeddings_for_cluster(user_id) for user_id in bot_source]\n",
    "\n",
    "# Separate the source_user_ids and embeddings into two lists\n",
    "source_ids, embeddings = zip(*aggregated_embeddings)\n",
    "\n",
    "# Convert the embeddings to a numpy array for use in K-means\n",
    "embeddings = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7tepqvFzuMez",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "7tepqvFzuMez",
    "outputId": "f4af4ab9-ef2f-4352-c7f2-572052a47dc3"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertia = []\n",
    "range_clusters = range(1, 15)\n",
    "\n",
    "for n_clusters in range_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(embeddings)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range_clusters, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LWctmR6IqrXc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWctmR6IqrXc",
    "outputId": "c16b79a8-d65d-470c-8273-b1738871af97"
   },
   "outputs": [],
   "source": [
    "n_clusters = 5  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "bot_clusters = kmeans.predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_clusters_ids = pd.DataFrame({'source_id': source_ids, 'cluster': bot_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X8ht0A0Ot5yG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8ht0A0Ot5yG",
    "outputId": "55f5a695-b107-4626-b4a4-2ccf4a494fc2"
   },
   "outputs": [],
   "source": [
    "bot_clusters_ids.to_csv('bot_clusters_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de2fdb",
   "metadata": {},
   "source": [
    "## Getting tweets from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a0ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Change your db and collection name accordingly\n",
    "hostname = 'localhost'\n",
    "port = 27017  \n",
    "client = MongoClient(hostname, port)\n",
    "db = client['bt4222']\n",
    "tweets = db['tweets1']\n",
    "file_num = 1 # change to which tweet.json you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79946937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cluster dataset\n",
    "bot_clusters = pd.read_csv(\"bot_clusters_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e73dfe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 done\n",
      "Cluster 1 done\n",
      "Cluster 2 done\n",
      "Cluster 3 done\n",
      "Cluster 4 done\n"
     ]
    }
   ],
   "source": [
    "for cluster_num in range(5):\n",
    "    cluster_ids = bot_clusters[bot_clusters['cluster'] == cluster_num]['source_id']\n",
    "    cluster_ids = cluster_ids.tolist()\n",
    "    pipeline = [\n",
    "        {'$match': {'lang': 'en'}},\n",
    "        {'$match': {'author_id': {'$in': cluster_ids}}},\n",
    "        {'$project': {'_id': 0, 'author_id': 1, 'text': 1}}\n",
    "    ]\n",
    "    tweet_cursor = tweets.aggregate(pipeline)\n",
    "    tweets_df = pd.DataFrame(list(tweet_cursor))\n",
    "    with open(f\"cluster_{cluster_num}_{file_num}.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "        for tweet in tweets_df['text']:\n",
    "            f.write(tweet + '\\n')\n",
    "        print(f\"Cluster {cluster_num} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832efab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
