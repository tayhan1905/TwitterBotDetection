{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tay Han\\AppData\\Local\\Temp\\ipykernel_16840\\577788817.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_0 = pd.read_csv('user_df_0.csv')\n",
    "user_1 = pd.read_csv('user_df_1.csv')\n",
    "user_2 = pd.read_csv('user_df_2.csv')\n",
    "user_3 = pd.read_csv('user_df_3.csv')\n",
    "user_4 = pd.read_csv('user_df_4.csv')\n",
    "user_5 = pd.read_csv('user_df_5.csv')\n",
    "user_6 = pd.read_csv('user_df_6.csv')\n",
    "user_7 = pd.read_csv('user_df_7.csv')\n",
    "user_8 = pd.read_csv('user_df_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(user_0) + len(user_1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking the CSVs together\n",
    "\n",
    "users = pd.concat([user_0,\n",
    "                user_1, \n",
    "                user_2,\n",
    "                user_3,\n",
    "                user_4, \n",
    "                user_5,\n",
    "                user_6,\n",
    "                user_7, \n",
    "                user_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9329"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregate all duplicate users within each sampling procedure\n",
    "log = {col: 'mean' if users[col].dtype in ['float64', 'int64'] else 'first' for col in users.columns if col != 'user_id'}\n",
    "\n",
    "users_result = users.groupby('user_id').agg(log).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0                      56808\n",
       "0                       9329\n",
       "1                       3657\n",
       "1                        496\n",
       "u952295114369654784        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_result[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all tweet relationships\n",
    "\n",
    "graph_0 = pd.read_csv('graph_df_0.csv')\n",
    "graph_1 = pd.read_csv('graph_df_1.csv')\n",
    "graph_2 = pd.read_csv('graph_df_2.csv')\n",
    "graph_3 = pd.read_csv('graph_df_3.csv')\n",
    "graph_4 = pd.read_csv('graph_df_4.csv')\n",
    "graph_5 = pd.read_csv('graph_df_5.csv')\n",
    "graph_6 = pd.read_csv('graph_df_6.csv')\n",
    "graph_7 = pd.read_csv('graph_df_7.csv')\n",
    "graph_8 = pd.read_csv('graph_df_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking the tweet CSVs together\n",
    "\n",
    "graph = pd.concat([graph_0,\n",
    "                graph_1, \n",
    "                graph_2,\n",
    "                graph_3,\n",
    "                graph_4, \n",
    "                graph_5,\n",
    "                graph_6,\n",
    "                graph_7, \n",
    "                graph_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tay Han\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "255245279",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m edge_weight_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 17\u001b[0m     source_idx \u001b[38;5;241m=\u001b[39m \u001b[43muser_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource_user_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     target_idx \u001b[38;5;241m=\u001b[39m user_to_idx[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_user_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     19\u001b[0m     idx_pair \u001b[38;5;241m=\u001b[39m (source_idx, target_idx)\n",
      "\u001b[1;31mKeyError\u001b[0m: 255245279"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a mapping of user IDs to node indices >> change it up to index\n",
    "user_ids = users[\"user_id\"]\n",
    "user_labels = users[\"label\"]\n",
    "user_to_idx = {user_id: idx for idx, user_id in enumerate(users[\"user_id\"])}\n",
    "\n",
    "# Create edge index and edge weight tensors\n",
    "edge_list = []\n",
    "edge_weight_dict = {}\n",
    "\n",
    "for _, row in graph.iterrows():\n",
    "    source_idx = user_to_idx[row['source_user_id']]\n",
    "    target_idx = user_to_idx[row['target_user_id']]\n",
    "    idx_pair = (source_idx, target_idx)\n",
    "    if (idx_pair not in edge_list) :\n",
    "        edge_list.append(idx_pair)\n",
    "        edge_weight_dict[idx_pair] = 1\n",
    "    else:\n",
    "        edge_weight_dict[idx_pair] += 1\n",
    "\n",
    "edge_weight_list = list(edge_weight_dict.values())\n",
    "\n",
    "#force it to be contiguous\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "edge_weight = torch.tensor(edge_weight_list, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>url_count_tweets</th>\n",
       "      <th>url_ratio</th>\n",
       "      <th>url_max_tweets</th>\n",
       "      <th>time_interval_sd_day</th>\n",
       "      <th>mention_count_tweets</th>\n",
       "      <th>mention_max_tweets</th>\n",
       "      <th>hashtag_count_tweets</th>\n",
       "      <th>hashtags_max_tweets</th>\n",
       "      <th>avg_tweet_length</th>\n",
       "      <th>url_tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, label, _id, created_at, description, id, location, name, profile_image_url, url, username, verified, url.urls, description.urls, description.mentions, description.hashtags, description.cashtags, followers_count, following_count, tweet_count, listed_count, source_user_id, username_length, name_length, description_length, numDigits_username, username_entropy, description_entropy, names_similarity, names_ratio, reputation, created_at_timestamp, age_of_account, retweet_ratio, url_count_tweets, url_ratio, url_max_tweets, time_interval_sd_day, mention_count_tweets, mention_max_tweets, hashtag_count_tweets, hashtags_max_tweets, avg_tweet_length, url_tweet_count]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 44 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[users['user_id'] == 255245279]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
