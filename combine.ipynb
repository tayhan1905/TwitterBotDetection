{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of CSVs\n",
    "- Due to the sheer size of the dataset (a total of 9 tweet data sets), we had to run the Feature Engineering script for each of the 9 tweet data sets and obtain the relevant information required from each dataset. \n",
    "- After which, we are able to concatenate them into two csv files `graph.csv` and `user.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Accessing all the relevant user information from the respective CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_0 = pd.read_csv('user_0.csv')\n",
    "user_1 = pd.read_csv('user_1.csv')\n",
    "user_2 = pd.read_csv('user_2.csv')\n",
    "user_3 = pd.read_csv('user_3.csv')\n",
    "user_4 = pd.read_csv('user_4.csv')\n",
    "user_5 = pd.read_csv('user_5.csv')\n",
    "user_6 = pd.read_csv('user_6.csv')\n",
    "user_7 = pd.read_csv('user_7.csv')\n",
    "user_8 = pd.read_csv('user_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking the CSVs together\n",
    "\n",
    "users = pd.concat([user_0,\n",
    "                user_1, \n",
    "                user_2,\n",
    "                user_3,\n",
    "                user_4, \n",
    "                user_5,\n",
    "                user_6,\n",
    "                user_7, \n",
    "                user_8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Aggregating all duplicate users within the sampling procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate all duplicate users within each sampling procedure\n",
    "log = {col: 'mean' if users[col].dtype in ['float64', 'int64'] and users[col] != 'source_user_id' else 'first' for col in users.columns if col != 'source_user_id'}\n",
    "\n",
    "users_result = users.groupby('source_user_id').agg(log).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    59769\n",
       "1.0    49656\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_result[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Accessing all the relevant graph information from the respective CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all tweet relationships\n",
    "\n",
    "graph_0 = pd.read_csv('graph_0.csv')\n",
    "graph_1 = pd.read_csv('graph_1.csv')\n",
    "graph_2 = pd.read_csv('graph_2.csv')\n",
    "graph_3 = pd.read_csv('graph_3.csv')\n",
    "graph_4 = pd.read_csv('graph_4.csv')\n",
    "graph_5 = pd.read_csv('graph_5.csv')\n",
    "graph_6 = pd.read_csv('graph_6.csv')\n",
    "graph_7 = pd.read_csv('graph_7.csv')\n",
    "graph_8 = pd.read_csv('graph_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking the tweet CSVs together\n",
    "\n",
    "graph = pd.concat([graph_0,\n",
    "                graph_1, \n",
    "                graph_2,\n",
    "                graph_3,\n",
    "                graph_4, \n",
    "                graph_5,\n",
    "                graph_6,\n",
    "                graph_7, \n",
    "                graph_8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save user data and graph data in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_result.to_csv(\"users.csv\", index = False)\n",
    "graph.to_csv(\"graph.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
